{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9390d3a2-e1cc-4c1f-bb42-c33d99ded218",
   "metadata": {},
   "source": [
    "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd548299-8620-4a8d-a733-c571230b1660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (4.14.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.12/site-packages (from konlpy) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.12/site-packages (from konlpy) (2.2.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
      "Hit:1 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "openjdk-11-jdk-headless is already the newest version (11.0.28+6-1ubuntu1~24.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
      "update-alternatives: warning: forcing reinstallation of alternative /usr/lib/jvm/java-11-openjdk-amd64/bin/java because link group java is broken\n",
      "update-alternatives: error: error creating symbolic link '/etc/alternatives/java.dpkg-tmp': Permission denied\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install konlpy\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y openjdk-11-jdk-headless\n",
    "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'\n",
    "import subprocess\n",
    "\n",
    "# Java ì„¤ì¹˜ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/default-java'\n",
    "os.environ['PATH'] = '/usr/lib/jvm/default-java/bin:' + os.environ.get('PATH', '')\n",
    "\n",
    "# ëŒ€ì•ˆ: Java ê²½ë¡œ ìë™ ì°¾ê¸°\n",
    "result = subprocess.run(['which', 'java'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    java_path = result.stdout.strip()\n",
    "    java_home = java_path.replace('/bin/java', '')\n",
    "    os.environ['JAVA_HOME'] = java_home\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b26e5-0ce5-4d63-81de-1f979381bf91",
   "metadata": {},
   "source": [
    "ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d561a2e-c44d-4de4-acd2-13e172ae0fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”</td>\n",
       "      <td>ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      class                                       conversation\n",
       "0           0      í˜‘ë°• ëŒ€í™”  ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...\n",
       "1           1      í˜‘ë°• ëŒ€í™”  ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...\n",
       "2           2  ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”  ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...\n",
       "3           3      ê°ˆì·¨ ëŒ€í™”  ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...\n",
       "4           4      ê°ˆì·¨ ëŒ€í™”  ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/train_w_general_conv.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ca35db-971e-4e83-bf0e-31e4cc036862",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed7f55b-0861-4abc-8ff7-5b73d9dd9f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”</td>\n",
       "      <td>ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                       conversation\n",
       "0      í˜‘ë°• ëŒ€í™”  ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...\n",
       "1      í˜‘ë°• ëŒ€í™”  ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...\n",
       "2  ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”  ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...\n",
       "3      ê°ˆì·¨ ëŒ€í™”  ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...\n",
       "4      ê°ˆì·¨ ëŒ€í™”  ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe97c69-9306-4780-a338-93dc3a1526f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ê°ˆì·¨ ëŒ€í™”</th>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”</th>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì¼ë°˜ ëŒ€í™”</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”</th>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>í˜‘ë°• ëŒ€í™”</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             conversation\n",
       "class                    \n",
       "ê°ˆì·¨ ëŒ€í™”                 981\n",
       "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”            1094\n",
       "ì¼ë°˜ ëŒ€í™”                1000\n",
       "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”           979\n",
       "í˜‘ë°• ëŒ€í™”                 896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8153fc19-4830-460c-8560-f021f9696154",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "stop_words = {\"í•˜ë‹¤\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c9e094-e047-42b4-86d1-fbbf62b7d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, stop_words):\n",
    "    # 1. ì–‘ìª½ ê³µë°± ì œê±°\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 2. íŠ¹ìˆ˜ë¬¸ì ë° ì´ëª¨ì§€ ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì ë§Œ í—ˆìš©)\n",
    "    sentence = re.sub(r\"[^ê°€-í£0-9a-zA-Z.,!?~\\s]\", \" \", sentence)\n",
    "\n",
    "    # 3. ì—°ì†ëœ ê³µë°± í•˜ë‚˜ë¡œ ì¶•ì†Œ ë° ì¤„ ë°”ê¿ˆ ë¬´ì‹œ\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "\n",
    "    # 4. ë¬¸ì¥ ë¶€í˜¸ ì•ë’¤ë¡œ ê³µë°± ì¶”ê°€ (í† í° êµ¬ë¶„ì„ ìœ„í•¨)\n",
    "    sentence = re.sub(r\"([?.!,~])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    \n",
    "    # í˜•íƒœì†Œ ë¶„ì„ (ë‹¨ì–´, í’ˆì‚¬)\n",
    "    include_tags = {\"Noun\", \"Verb\", \"Adjective\", \"Exclamation\", \"Adverb\"}\n",
    "    pos_tags = okt.pos(sentence, stem=True, norm=True)\n",
    "    # ì›í•˜ëŠ” í’ˆì‚¬ë§Œ ì¶”ì¶œ\n",
    "    tokens = [\n",
    "        word for word, tag in pos_tags\n",
    "        if tag in include_tags and len(word) > 0 and word not in stop_words\n",
    "    ]\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fc93fd-9f7f-451f-b5c3-a8c4930401c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì§€ê¸ˆ', 'ë„ˆ', 'ìŠ¤ìŠ¤ë¡œ', 'ì£½ì´ë‹¤', 'ë‹¬ë¼', 'ì• ì›', 'ê²ƒ', 'ì•„ë‹ˆë‹¤', 'ì£„ì†¡í•˜ë‹¤', 'ì£½', 'ê±°', 'í˜¼ì', 'ì£½ì§€', 'ìš°ë¦¬', 'ì‚¬ê±´', 'íœ˜', 'ë§ë¦¬', 'í•´', 'ì§„ì§œ', 'ì£½ì´ë‹¤', 'ë²„ë¦¬ë‹¤', 'ì‹¶ë‹¤', 'ì •ë§', 'ë„ˆ', 'ì„ íƒ', 'ë„ˆ', 'ì£½ë‹¤', 'ë„¤', 'ê°€ì¡±', 'ì£½ì—¬ì£¼ë‹¤', 'ì£„ì†¡í•˜ë‹¤', 'ì •ë§', 'ë„ˆ', 'ì„ íƒ', 'ì—†ë‹¤', 'ì„ íƒ', 'ë„ˆ', 'ë„¤', 'ê°€ì¡±', 'ëª¨ì¡°ë¦¬', 'ì£½ì´ë‹¤', 'ë²„ë¦¬ë‹¤', 'ì„ íƒ', 'í•œë²ˆ', 'ë„ì™€ì£¼ë‹¤', 'ê·¸ëƒ¥', 'ë‹¤', 'ì£½ì´ë‹¤', 'ë²„ë¦¬ë‹¤', 'ì´ì˜', 'ì—†ë‹¤', 'ì œë°œ', 'ë„ì™€ì£¼ë‹¤']\n"
     ]
    }
   ],
   "source": [
    "sample_text = raw_data['conversation'][0]\n",
    "tokens = preprocess_sentence(sample_text, stop_words)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9bb624-1ee9-4f25-a097-6ee893d00f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...</td>\n",
       "      <td>[ì§€ê¸ˆ, ë„ˆ, ìŠ¤ìŠ¤ë¡œ, ì£½ì´ë‹¤, ë‹¬ë¼, ì• ì›, ê²ƒ, ì•„ë‹ˆë‹¤, ì£„ì†¡í•˜ë‹¤, ì£½, ê±°, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>í˜‘ë°• ëŒ€í™”</td>\n",
       "      <td>ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...</td>\n",
       "      <td>[ê¸¸ë™, ê²½ì°°ì„œ, ì´ë‹¤, ë§ˆíŠ¸, í­ë°œë¬¼, ì„¤ì¹˜, ë„¤, ë˜‘ë°”ë¡œ, ë“¤ë‹¤, í•œë²ˆ, ë”, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”</td>\n",
       "      <td>ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...</td>\n",
       "      <td>[ë„ˆ, ë˜ê²Œ, ê·€ì—½ë‹¤, ì•Œ, ë‚˜, ì‘ë‹¤, ë‚¨ì, ì²¨, ë³´ë‹¤, ê·¸ë§Œí•˜ë‹¤, ë‹ˆ, ë†€ë¦¬ë‹¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...</td>\n",
       "      <td>[ì–´ì´, ê±°ê¸°, ì˜ˆ, ë„ˆ, ë§, ë„ˆ, ì´ë¦¬, ì˜¤ë¼, ë¬´ìŠ¨, ì¼, ë„ˆ, ì˜·, ì¢‹ë‹¤, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê°ˆì·¨ ëŒ€í™”</td>\n",
       "      <td>ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ...</td>\n",
       "      <td>[ì €ê¸°, í˜¹ì‹œ, ë‚ , ë„ˆë¬´, ëœ¨ê²ë‹¤, ì €í¬, íšŒì‚¬, ì´, ì„ í¬ë¦¼, íŒ”ë‹¤, ë²ˆ, ì†ë“±...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                       conversation  \\\n",
       "0      í˜‘ë°• ëŒ€í™”  ì§€ê¸ˆ ë„ˆ ìŠ¤ìŠ¤ë¡œë¥¼ ì£½ì—¬ë‹¬ë¼ê³  ì• ì›í•˜ëŠ” ê²ƒì¸ê°€?\\n ì•„ë‹™ë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤.\\n ì£½ì„ ...   \n",
       "1      í˜‘ë°• ëŒ€í™”  ê¸¸ë™ê²½ì°°ì„œì…ë‹ˆë‹¤.\\n9ì‹œ 40ë¶„ ë§ˆíŠ¸ì— í­ë°œë¬¼ì„ ì„¤ì¹˜í• ê±°ë‹¤.\\në„¤?\\në˜‘ë°”ë¡œ ë“¤ì–´ ...   \n",
       "2  ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”  ë„ˆ ë˜ê²Œ ê·€ì—¬ìš´ê±° ì•Œì§€? ë‚˜ë³´ë‹¤ ì‘ì€ ë‚¨ìëŠ” ì²¨ë´¤ì–´.\\nê·¸ë§Œí•´. ë‹ˆë“¤ ë†€ë¦¬ëŠ”ê±° ì¬ë¯¸...   \n",
       "3      ê°ˆì·¨ ëŒ€í™”  ì–´ì´ ê±°ê¸°\\nì˜ˆ??\\në„ˆ ë§ì´ì•¼ ë„ˆ. ì´ë¦¬ ì˜¤ë¼ê³ \\në¬´ìŠ¨ ì¼.\\në„ˆ ì˜· ì¢‹ì•„ë³´ì¸ë‹¤?...   \n",
       "4      ê°ˆì·¨ ëŒ€í™”  ì €ê¸°ìš” í˜¹ì‹œ ë‚ ì´ ë„ˆë¬´ ëœ¨ê²ì–ì•„ìš”? ì €í¬ íšŒì‚¬ì—ì„œ ì´ ì„ í¬ë¦¼ íŒŒëŠ”ë° í•œ ë²ˆ ì†ë“±ì— ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [ì§€ê¸ˆ, ë„ˆ, ìŠ¤ìŠ¤ë¡œ, ì£½ì´ë‹¤, ë‹¬ë¼, ì• ì›, ê²ƒ, ì•„ë‹ˆë‹¤, ì£„ì†¡í•˜ë‹¤, ì£½, ê±°, ...  \n",
       "1  [ê¸¸ë™, ê²½ì°°ì„œ, ì´ë‹¤, ë§ˆíŠ¸, í­ë°œë¬¼, ì„¤ì¹˜, ë„¤, ë˜‘ë°”ë¡œ, ë“¤ë‹¤, í•œë²ˆ, ë”, ...  \n",
       "2  [ë„ˆ, ë˜ê²Œ, ê·€ì—½ë‹¤, ì•Œ, ë‚˜, ì‘ë‹¤, ë‚¨ì, ì²¨, ë³´ë‹¤, ê·¸ë§Œí•˜ë‹¤, ë‹ˆ, ë†€ë¦¬ë‹¤...  \n",
       "3  [ì–´ì´, ê±°ê¸°, ì˜ˆ, ë„ˆ, ë§, ë„ˆ, ì´ë¦¬, ì˜¤ë¼, ë¬´ìŠ¨, ì¼, ë„ˆ, ì˜·, ì¢‹ë‹¤, ...  \n",
       "4  [ì €ê¸°, í˜¹ì‹œ, ë‚ , ë„ˆë¬´, ëœ¨ê²ë‹¤, ì €í¬, íšŒì‚¬, ì´, ì„ í¬ë¦¼, íŒ”ë‹¤, ë²ˆ, ì†ë“±...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['tokens'] = raw_data['conversation'].apply(lambda x: preprocess_sentence(str(x), stop_words))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595a09bf-724d-41b8-8bce-fa7d90b907c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë¬¸: ì•ˆë…•í•˜ì„¸ìš”!! ì €ëŠ” ë°ì´í„° ë¶„ì„ì„ ì¢‹ì•„í•´ìš”~~ ğŸ˜Š\n",
      "ì „ì²˜ë¦¬ ê²°ê³¼: ['ì•ˆë…•í•˜ë‹¤', 'ì €', 'ë°ì´í„°', 'ë¶„ì„', 'ì¢‹ì•„í•˜ë‹¤']\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"ì•ˆë…•í•˜ì„¸ìš”!! ì €ëŠ” ë°ì´í„° ë¶„ì„ì„ ì¢‹ì•„í•´ìš”~~ ğŸ˜Š\"\n",
    "result = preprocess_sentence(sample_sentence, stop_words)\n",
    "print(f\"ì›ë¬¸: {sample_sentence}\")\n",
    "print(f\"ì „ì²˜ë¦¬ ê²°ê³¼: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cd9eb3-e5cc-4033-b9ce-1bbcfd238aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Vocab ë¹Œë“œ =====\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "import json\n",
    "\n",
    "SPECIALS = [\"<pad>\", \"<unk>\", \"<cls>\", \"<sep>\"]\n",
    "\n",
    "def build_vocab(\n",
    "    token_lists: Iterable[List[str]],\n",
    "    min_freq: int = 2,\n",
    "    max_size: int = 30000,\n",
    "    specials: List[str] = SPECIALS,\n",
    ") -> Tuple[Dict[str, int], List[str], Counter]:\n",
    "    \"\"\"\n",
    "    token_lists: ê° ìƒ˜í”Œì˜ í† í° ë¦¬ìŠ¤íŠ¸(iterable of list[str])\n",
    "    min_freq: ìµœì†Œ ë“±ì¥ ë¹ˆë„ ë¯¸ë§Œ í† í°ì€ ì œì™¸\n",
    "    max_size: special í¬í•¨ ì „ì²´ vocab ìƒí•œ (Noneì´ë©´ ì œí•œ ì—†ìŒ)\n",
    "    returns: (stoi, itos, counter)\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for toks in token_lists:\n",
    "        counter.update(toks)\n",
    "\n",
    "    # ë¹ˆë„ í•„í„° + ìƒìœ„ max_size-íŠ¹ìˆ˜í† í° ë§Œí¼\n",
    "    most = [tok for tok, cnt in counter.most_common() if cnt >= min_freq]\n",
    "    if max_size is not None:\n",
    "        cap = max_size - len(specials)\n",
    "        most = most[:max(0, cap)]\n",
    "\n",
    "    itos = list(specials) + most\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos, counter\n",
    "\n",
    "def save_vocab(path: str, itos: List[str]) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(itos, f, ensure_ascii=False)\n",
    "\n",
    "def load_vocab(path: str) -> Tuple[Dict[str, int], List[str]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        itos = json.load(f)\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7637ca8-9d04-48e7-9b37-1a3a15a8b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2) í† í° â†’ ID ì¸ì½”ë”© =====\n",
    "def encode_tokens(\n",
    "    tokens: List[str],\n",
    "    stoi: Dict[str, int],\n",
    "    max_len: int = 256,\n",
    "    add_cls: bool = True,\n",
    "    add_sep: bool = True,\n",
    ") -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    tokens -> input_ids, attention_mask\n",
    "    - OOVëŠ” <unk>\n",
    "    - <cls>, <sep>ë¥¼ ì˜µì…˜ìœ¼ë¡œ ì•/ë’¤ì— ë¶€ì°©\n",
    "    - max_lenì„ ì´ˆê³¼í•˜ë©´ ì ì ˆíˆ ìë¦„\n",
    "    \"\"\"\n",
    "    pad_id = stoi[\"<pad>\"]\n",
    "    unk_id = stoi[\"<unk>\"]\n",
    "    cls_id = stoi.get(\"<cls>\")\n",
    "    sep_id = stoi.get(\"<sep>\")\n",
    "\n",
    "    ids = [stoi.get(t, unk_id) for t in tokens]\n",
    "\n",
    "    # ê¸¸ì´ ê³„ì‚° (cls/sep í¬í•¨í•´ì„œ ìë¥´ê¸°)\n",
    "    extra = (1 if add_cls else 0) + (1 if add_sep else 0)\n",
    "    keep = max_len - extra\n",
    "    keep = max(0, keep)\n",
    "    ids = ids[:keep]\n",
    "\n",
    "    if add_cls:\n",
    "        ids = [cls_id] + ids\n",
    "    if add_sep:\n",
    "        ids = ids + [sep_id]\n",
    "\n",
    "    attn = [1] * len(ids)\n",
    "    return ids, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b1c200-4f8e-4fa8-aa82-bf82675872f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) ë°°ì¹˜ íŒ¨ë”©(collate) =====\n",
    "import torch\n",
    "\n",
    "def collate_batch(\n",
    "    batch,\n",
    "    pad_id: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    batch: [{\"input_ids\": List[int], \"attention_mask\": List[int], \"label\": int}, ...]\n",
    "    \"\"\"\n",
    "    bs = len(batch)\n",
    "    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = torch.full((bs, maxlen), pad_id, dtype=torch.long)\n",
    "    attention_mask = torch.zeros((bs, maxlen), dtype=torch.long)\n",
    "    labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.long)\n",
    "\n",
    "    for i, x in enumerate(batch):\n",
    "        L = len(x[\"input_ids\"])\n",
    "        input_ids[i, :L] = torch.tensor(x[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask[i, :L] = torch.tensor(x[\"attention_mask\"], dtype=torch.long)\n",
    "\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d543b95c-15b7-4ee6-bce4-4d817f85e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 10156 | Labels: {'í˜‘ë°• ëŒ€í™”': 0, 'ê°ˆì·¨ ëŒ€í™”': 1, 'ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”': 2, 'ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”': 3, 'ì¼ë°˜ ëŒ€í™”': 4}\n",
      "torch.Size([16, 103])\n"
     ]
    }
   ],
   "source": [
    "# ===== 4) ì˜ˆì‹œ íŒŒì´í”„ë¼ì¸ (ë¼ë²¨ ë§¤í•‘ í¬í•¨) =====\n",
    "# 4-1) tokens ì»¬ëŸ¼ì´ ì—†ë‹¤ë©´ ë¨¼ì € ìƒì„±\n",
    "# raw_data['tokens'] = raw_data['conversation'].apply(lambda s: preprocess_sentence(str(s), stop_words))\n",
    "\n",
    "# 4-2) ë¼ë²¨ ë§¤í•‘\n",
    "labels = sorted(raw_data[\"class\"].unique().tolist())\n",
    "label2id = {\n",
    "    \"í˜‘ë°• ëŒ€í™”\": 0,\n",
    "    \"ê°ˆì·¨ ëŒ€í™”\": 1,\n",
    "    \"ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”\": 2,\n",
    "    \"ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”\": 3,\n",
    "    \"ì¼ë°˜ ëŒ€í™”\": 4,\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# 4-3) vocab ë¹Œë“œ\n",
    "stoi, itos, counter = build_vocab(raw_data[\"tokens\"], min_freq=1, max_size=20000)\n",
    "pad_id = stoi[\"<pad>\"]\n",
    "\n",
    "# 4-4) ì¸ì½”ë”© (train/valid ë¶„í• ì€ ì´ë¯¸ ë˜ì–´ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜ ì•„ë˜ì²˜ëŸ¼ ê°„ë‹¨ ë¶„í• )\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(raw_data, test_size=0.2, random_state=42, stratify=raw_data[\"class\"])\n",
    "\n",
    "def encode_row(row, max_len=256):\n",
    "    ids, attn = encode_tokens(row[\"tokens\"], stoi, max_len=max_len, add_cls=True, add_sep=True)\n",
    "    return {\n",
    "        \"input_ids\": ids,\n",
    "        \"attention_mask\": attn,\n",
    "        \"label\": label2id[row[\"class\"]],\n",
    "    }\n",
    "\n",
    "train_records = [encode_row(r) for _, r in train_df.iterrows()]\n",
    "valid_records = [encode_row(r) for _, r in valid_df.iterrows()]\n",
    "\n",
    "# 4-5) PyTorch Dataset/Dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleListDataset(Dataset):\n",
    "    def __init__(self, records):\n",
    "        self.records = records\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.records[idx]\n",
    "\n",
    "train_ds = SimpleListDataset(train_records)\n",
    "valid_ds = SimpleListDataset(valid_records)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,\n",
    "                          collate_fn=lambda b: collate_batch(b, pad_id))\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=False,\n",
    "                          collate_fn=lambda b: collate_batch(b, pad_id))\n",
    "\n",
    "print(f\"Vocab size: {len(itos)} | Labels: {label2id}\")\n",
    "print(next(iter(train_loader))[\"input_ids\"].shape)  # (B, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677cdf4b-b909-407a-9c0d-0ee89d71d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LSTM Classifier ì •ì˜ =====\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM ê¸°ë°˜ ë¬¸ì„œ/ëŒ€í™” ë¶„ë¥˜ê¸°\n",
    "    - input_ids: (B, S) í† í° ì¸ë±ìŠ¤\n",
    "    - attention_mask: (B, S) 1=ìœ íš¨, 0=íŒ¨ë”©\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        num_classes: int,\n",
    "        emb_dim: int = 256,\n",
    "        hidden_dim: int = 512,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "        bidirectional: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.norm = nn.LayerNorm(lstm_output_dim)\n",
    "        self.classifier = nn.Linear(lstm_output_dim, num_classes)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor = None,\n",
    "        return_repr: bool = False,\n",
    "    ):\n",
    "        x = self.emb(input_ids)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            lengths = attention_mask.sum(dim=1).cpu()\n",
    "            x_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x, lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            lstm_out, (h_n, c_n) = self.lstm(x_packed)\n",
    "            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        else:\n",
    "            lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        if self.lstm.bidirectional:\n",
    "            sent_repr = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "        else:\n",
    "            sent_repr = h_n[-1]\n",
    "        \n",
    "        sent_repr = self.norm(sent_repr)\n",
    "        logits = self.classifier(sent_repr)\n",
    "        \n",
    "        if return_repr:\n",
    "            return logits, sent_repr\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1197f8aa-ba5f-46f8-8b6f-04317b9fab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== í•™ìŠµ/í‰ê°€ ë£¨í”„ =====\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    class_weights: torch.Tensor = None,\n",
    "    grad_clip: float = 1.0,\n",
    "    scheduler = None,\n",
    "    use_amp: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    ce = nn.CrossEntropyLoss(weight=class_weights.to(device) if class_weights is not None else None)\n",
    "    \n",
    "    losses, all_preds, all_labels = [], [], []\n",
    "    for batch in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn = batch.get(\"attention_mask\")\n",
    "        attn = attn.to(device) if attn is not None else None\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            logits = model(input_ids, attention_mask=attn)\n",
    "            loss = ce(logits, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        if grad_clip is not None:\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        all_preds += logits.argmax(dim=-1).detach().cpu().tolist()\n",
    "        all_labels += labels.detach().cpu().tolist()\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    return {\"loss\": sum(losses)/len(losses), \"acc\": acc, \"f1_macro\": f1}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses, all_preds, all_labels = [], [], []\n",
    "    for batch in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn = batch.get(\"attention_mask\")\n",
    "        attn = attn.to(device) if attn is not None else None\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        logits = model(input_ids, attention_mask=attn)\n",
    "        loss = ce(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        all_preds += logits.argmax(dim=-1).detach().cpu().tolist()\n",
    "        all_labels += labels.detach().cpu().tolist()\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds) if all_labels else 0.0\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\") if all_labels else 0.0\n",
    "    return {\"loss\": sum(losses)/len(losses), \"acc\": acc, \"f1_macro\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac0e3025-1199-4ff4-b6ac-7a94d0344e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ëª¨ë¸ íŒ©í† ë¦¬ =====\n",
    "def create_model(\n",
    "    vocab_size: int,\n",
    "    num_classes: int = 5,\n",
    "    pad_id: int = 0,\n",
    "    emb_dim: int = 256,\n",
    "    hidden_dim: int = 512,\n",
    "    num_layers: int = 2,\n",
    "    dropout: float = 0.1,\n",
    "    bidirectional: bool = True,\n",
    ") -> nn.Module:\n",
    "    return LSTMClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_classes=num_classes,\n",
    "        emb_dim=emb_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        pad_id=pad_id,\n",
    "        bidirectional=bidirectional,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43296a53-2aba-4759-97ff-23eec8b174c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ëª¨ë¸ ìƒì„± ë° ì„¤ì • =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = create_model(\n",
    "    vocab_size=len(itos),\n",
    "    num_classes=5,\n",
    "    pad_id=stoi[\"<pad>\"],\n",
    "    emb_dim=256,\n",
    "    hidden_dim=512,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    bidirectional=True,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "scheduler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f9b324b-7616-4570-a7da-61890458a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac08aa88df643b095c8c7b52600f2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4848d30314540468ca87b5b5dc407c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] train: {'loss': 0.04019874006066946, 'acc': 0.9881313131313131, 'f1_macro': 0.9880504008229269} | valid: {'loss': 1.557276927340295, 'acc': 0.8494949494949495, 'f1_macro': 0.8490025659770156}\n",
      "  âœ” saved best model (F1 â†‘)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a8dafcfab046ef894d63c0f6aa7591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e595d94aabd4dd280ee88e522da31c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02] train: {'loss': 0.0458231176189997, 'acc': 0.9873737373737373, 'f1_macro': 0.9872812134246575} | valid: {'loss': 1.764549434185028, 'acc': 0.8323232323232324, 'f1_macro': 0.8305296953023401}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4751c1697a224377920a34394192829c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23376ff05abe43e9b70511cdb92a0fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03] train: {'loss': 0.048941250922169395, 'acc': 0.9904040404040404, 'f1_macro': 0.9904930744169494} | valid: {'loss': 1.6287912332242536, 'acc': 0.8262626262626263, 'f1_macro': 0.8280319684478188}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d17330096c44e98cef83fc1b3b2710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a99e96ff841403b84602d1c6e7646b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04] train: {'loss': 0.023649174930438166, 'acc': 0.9939393939393939, 'f1_macro': 0.9938401884671639} | valid: {'loss': 1.705227824949449, 'acc': 0.8282828282828283, 'f1_macro': 0.8283216678943155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74c73b485d0430ebac43f49fa5fab7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2872/3461024018.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea35bb420d774c7e9d353b97139cbaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05] train: {'loss': 0.036443779626466104, 'acc': 0.9921717171717171, 'f1_macro': 0.9921349682968085} | valid: {'loss': 1.7345652748500147, 'acc': 0.8373737373737373, 'f1_macro': 0.8373719606490736}\n"
     ]
    }
   ],
   "source": [
    "# ===== í•™ìŠµ ì‹¤í–‰ =====\n",
    "from collections import Counter\n",
    "\n",
    "train_labels = [rec[\"label\"] for rec in train_records]\n",
    "cnt = Counter(train_labels)\n",
    "weights = torch.tensor([1.0 / max(cnt.get(i, 1), 1) for i in range(5)], dtype=torch.float)\n",
    "weights = weights / weights.mean()\n",
    "class_weights = weights\n",
    "\n",
    "best_f1 = 0.0\n",
    "epochs = 5\n",
    "for ep in range(1, epochs+1):\n",
    "    tr = train_one_epoch(model, train_loader, optimizer, device,\n",
    "                         class_weights=class_weights, grad_clip=1.0, scheduler=scheduler, use_amp=True)\n",
    "    va = evaluate(model, valid_loader, device)\n",
    "    print(f\"[{ep:02d}] train: {tr} | valid: {va}\")\n",
    "    \n",
    "    if va[\"f1_macro\"] > best_f1:\n",
    "        best_f1 = va[\"f1_macro\"]\n",
    "        torch.save(model.state_dict(), f\"./{best_f1:.4f}_best_lstm_cls.pt\")\n",
    "        print(\"  âœ” saved best model (F1 â†‘)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c75f0286-10f1-4be4-800b-866ff5aff595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ =====\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— í† í°í™” ì ìš©\n",
    "test_data['tokens'] = test_data['conversation'].apply(lambda x: preprocess_sentence(str(x), stop_words))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¸ì½”ë”©\n",
    "def encode_test_row(row, max_len=256):\n",
    "    ids, attn = encode_tokens(row[\"tokens\"], stoi, max_len=max_len, add_cls=True, add_sep=True)\n",
    "    return {\n",
    "        \"input_ids\": ids,\n",
    "        \"attention_mask\": attn,\n",
    "    }\n",
    "\n",
    "test_records = [encode_test_row(r) for _, r in test_data.iterrows()]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, records):\n",
    "        self.records = records\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.records[idx]\n",
    "\n",
    "def collate_test_batch(batch, pad_id: int):\n",
    "    bs = len(batch)\n",
    "    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = torch.full((bs, maxlen), pad_id, dtype=torch.long)\n",
    "    attention_mask = torch.zeros((bs, maxlen), dtype=torch.long)\n",
    "    \n",
    "    for i, x in enumerate(batch):\n",
    "        L = len(x[\"input_ids\"])\n",
    "        input_ids[i, :L] = torch.tensor(x[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask[i, :L] = torch.tensor(x[\"attention_mask\"], dtype=torch.long)\n",
    "    \n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "test_ds = TestDataset(test_records)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False,\n",
    "                         collate_fn=lambda b: collate_test_batch(b, pad_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fd87208-c463-4649-9af8-2bdc2ef68c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818a3d0a6d4e423f99bf4d789ef0686d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì™„ë£Œ! ì´ 500ê°œì˜ ìƒ˜í”Œì„ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.\n",
      "ê²°ê³¼ê°€ './data/submission.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆì¸¡ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\n",
      "     idx  class\n",
      "0  t_000      1\n",
      "1  t_001      2\n",
      "2  t_002      2\n",
      "3  t_003      2\n",
      "4  t_004      3\n",
      "5  t_005      0\n",
      "6  t_006      0\n",
      "7  t_007      1\n",
      "8  t_008      3\n",
      "9  t_009      1\n"
     ]
    }
   ],
   "source": [
    "# ===== ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ =====\n",
    "# ì €ì¥ëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
    "model.load_state_dict(torch.load(f\"./{best_f1:.4f}_best_lstm_cls.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        logits = model(input_ids, attention_mask=attn)\n",
    "        preds = logits.argmax(dim=-1).cpu().tolist()\n",
    "        all_predictions.extend(preds)\n",
    "\n",
    "# ===== submission.csv ìƒì„± =====\n",
    "# ì¸ë±ìŠ¤ ìƒì„± (t_000, t_001, ...)\n",
    "indices = [f\"t_{i:03d}\" for i in range(len(all_predictions))]\n",
    "\n",
    "# ê²°ê³¼ DataFrame ìƒì„±\n",
    "submission_df = pd.DataFrame({\n",
    "    'idx': indices,\n",
    "    'class': all_predictions\n",
    "})\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "submission_df.to_csv('./data/submission.csv', index=False)\n",
    "\n",
    "print(f\"ì˜ˆì¸¡ ì™„ë£Œ! ì´ {len(all_predictions)}ê°œì˜ ìƒ˜í”Œì„ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ê²°ê³¼ê°€ './data/submission.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"\\nì˜ˆì¸¡ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(submission_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa79cec-768a-41b9-bea0-63f6a46e1189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc49a7c7-e462-4b27-8d2b-36557e739b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 사전 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae58d0-9c14-4c0d-9dd2-ed091fb7454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install konlpy\n",
    "!pip install torch\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y fonts-nanum fonts-noto-cjk\n",
    "!fc-list | grep -i \"nanum\\|noto\"\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install openjdk-11-jdk -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406d894-c17c-4cab-b4a5-04286c4ad809",
   "metadata": {},
   "source": [
    "# Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e19f7bfe-cb57-49ee-a4ea-bfcbbd35634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Optional, Dict\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../data/'\n",
    "train = pd.read_csv(url+'train.csv')\n",
    "\n",
    "# 지연님 생성 데이터\n",
    "a = pd.read_csv(url+'general_dialog1.csv').rename(columns={'dialogue': 'conversation'})\n",
    "a['class'] = '일반 대화'\n",
    "a['idx'] = range(0,len(a))\n",
    "a = a[['idx','class','conversation']]\n",
    "\n",
    "# 유찬님 생성 데이터\n",
    "b = pd.read_csv(url+'general_dialog2.csv')\n",
    "b = b[b['class'] == \"일반 대화\"] # class에 일반대화가 아닌 conversation이 적혀있어 제거\n",
    "\n",
    "train = pd.concat([train, a, b], axis=0,ignore_index=True).drop(columns='idx')\n",
    "train.to_csv(url+\"train_w_general_conv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b09628e9-9a4e-48b9-b9d7-0e567fb92684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      class                                       conversation\n",
       "0           0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1           1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2           2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3           3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4           4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/train_w_general_conv.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca7d5778-06d5-4880-9471-13e4e928da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f188590d-8777-4d47-a7fa-c2b1a105580d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                       conversation\n",
       "0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "006a3800-6a70-4a3e-b77a-227cd7b48c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>갈취 대화</th>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기타 괴롭힘 대화</th>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일반 대화</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>직장 내 괴롭힘 대화</th>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>협박 대화</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             conversation\n",
       "class                    \n",
       "갈취 대화                 981\n",
       "기타 괴롭힘 대화            1094\n",
       "일반 대화                1000\n",
       "직장 내 괴롭힘 대화           979\n",
       "협박 대화                 896"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90c16324-1aa2-4456-a65e-a3150f7e9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "stop_words = {\"하다\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b2876c4-5349-40aa-97c4-ac3ba88520d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, stop_words):\n",
    "    # 1. 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 2. 특수문자 및 이모지 제거 (한글, 영어, 숫자, 기본 구두점만 허용)\n",
    "    sentence = re.sub(r\"[^가-힣0-9a-zA-Z.,!?~\\s]\", \" \", sentence)\n",
    "\n",
    "    # 3. 연속된 공백 하나로 축소 및 줄 바꿈 무시\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "\n",
    "    # 4. 문장 부호 앞뒤로 공백 추가 (토큰 구분을 위함)\n",
    "    sentence = re.sub(r\"([?.!,~])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    \n",
    "    # 형태소 분석 (단어, 품사)\n",
    "    include_tags = {\"Noun\", \"Verb\", \"Adjective\", \"Exclamation\", \"Adverb\"}\n",
    "    pos_tags = okt.pos(sentence, stem=True, norm=True)\n",
    "    # 원하는 품사만 추출\n",
    "    tokens = [\n",
    "        word for word, tag in pos_tags\n",
    "        if tag in include_tags and len(word) > 1 and word not in stop_words\n",
    "    ]\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1337f999-c4c4-48ea-b49e-3a7249e9ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['지금', '스스로', '죽이다', '달라', '애원', '아니다', '죄송하다', '혼자', '죽지', '우리', '사건', '말리', '진짜', '죽이다', '버리다', '싶다', '정말', '선택', '죽다', '가족', '죽여주다', '죄송하다', '정말', '선택', '없다', '선택', '가족', '모조리', '죽이다', '버리다', '선택', '한번', '도와주다', '그냥', '죽이다', '버리다', '이의', '없다', '제발', '도와주다']\n"
     ]
    }
   ],
   "source": [
    "sample_text = raw_data['conversation'][0]\n",
    "tokens = preprocess_sentence(sample_text, stop_words)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a999961-c023-4792-ba7f-4fe6273f655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>[지금, 스스로, 죽이다, 달라, 애원, 아니다, 죄송하다, 혼자, 죽지, 우리, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>[길동, 경찰서, 이다, 마트, 폭발물, 설치, 똑바로, 들다, 한번, 얘기, 장난...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>[되게, 귀엽다, 작다, 남자, 보다, 그만하다, 놀리다, 재미없다, 지영, 이지,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>[어이, 거기, 이리, 오라, 무슨, 좋다, 보이다, 있다, 보다, 아니다, 없다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>[저기, 혹시, 너무, 뜨겁다, 저희, 회사, 선크림, 팔다, 손등, 발라, 보다,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                       conversation  \\\n",
       "0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [지금, 스스로, 죽이다, 달라, 애원, 아니다, 죄송하다, 혼자, 죽지, 우리, ...  \n",
       "1  [길동, 경찰서, 이다, 마트, 폭발물, 설치, 똑바로, 들다, 한번, 얘기, 장난...  \n",
       "2  [되게, 귀엽다, 작다, 남자, 보다, 그만하다, 놀리다, 재미없다, 지영, 이지,...  \n",
       "3  [어이, 거기, 이리, 오라, 무슨, 좋다, 보이다, 있다, 보다, 아니다, 없다,...  \n",
       "4  [저기, 혹시, 너무, 뜨겁다, 저희, 회사, 선크림, 팔다, 손등, 발라, 보다,...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['tokens'] = raw_data['conversation'].apply(lambda x: preprocess_sentence(str(x), stop_words))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a388765-02ab-43b5-8407-e30149742bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Vocab 빌드 =====\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "import json\n",
    "\n",
    "SPECIALS = [\"<pad>\", \"<unk>\", \"<cls>\", \"<sep>\"]\n",
    "\n",
    "def build_vocab(\n",
    "    token_lists: Iterable[List[str]],\n",
    "    min_freq: int = 2,\n",
    "    max_size: int = 30000,\n",
    "    specials: List[str] = SPECIALS,\n",
    ") -> Tuple[Dict[str, int], List[str], Counter]:\n",
    "    \"\"\"\n",
    "    token_lists: 각 샘플의 토큰 리스트(iterable of list[str])\n",
    "    min_freq: 최소 등장 빈도 미만 토큰은 제외\n",
    "    max_size: special 포함 전체 vocab 상한 (None이면 제한 없음)\n",
    "    returns: (stoi, itos, counter)\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for toks in token_lists:\n",
    "        counter.update(toks)\n",
    "\n",
    "    # 빈도 필터 + 상위 max_size-특수토큰 만큼\n",
    "    most = [tok for tok, cnt in counter.most_common() if cnt >= min_freq]\n",
    "    if max_size is not None:\n",
    "        cap = max_size - len(specials)\n",
    "        most = most[:max(0, cap)]\n",
    "\n",
    "    itos = list(specials) + most\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos, counter\n",
    "\n",
    "def save_vocab(path: str, itos: List[str]) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(itos, f, ensure_ascii=False)\n",
    "\n",
    "def load_vocab(path: str) -> Tuple[Dict[str, int], List[str]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        itos = json.load(f)\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "decea60d-879c-41ac-8400-92f92a826963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2) 토큰 → ID 인코딩 =====\n",
    "def encode_tokens(\n",
    "    tokens: List[str],\n",
    "    stoi: Dict[str, int],\n",
    "    max_len: int = 256,\n",
    "    add_cls: bool = True,\n",
    "    add_sep: bool = True,\n",
    ") -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    tokens -> input_ids, attention_mask\n",
    "    - OOV는 <unk>\n",
    "    - <cls>, <sep>를 옵션으로 앞/뒤에 부착\n",
    "    - max_len을 초과하면 적절히 자름\n",
    "    \"\"\"\n",
    "    pad_id = stoi[\"<pad>\"]\n",
    "    unk_id = stoi[\"<unk>\"]\n",
    "    cls_id = stoi.get(\"<cls>\")\n",
    "    sep_id = stoi.get(\"<sep>\")\n",
    "\n",
    "    ids = [stoi.get(t, unk_id) for t in tokens]\n",
    "\n",
    "    # 길이 계산 (cls/sep 포함해서 자르기)\n",
    "    extra = (1 if add_cls else 0) + (1 if add_sep else 0)\n",
    "    keep = max_len - extra\n",
    "    keep = max(0, keep)\n",
    "    ids = ids[:keep]\n",
    "\n",
    "    if add_cls:\n",
    "        ids = [cls_id] + ids\n",
    "    if add_sep:\n",
    "        ids = ids + [sep_id]\n",
    "\n",
    "    attn = [1] * len(ids)\n",
    "    return ids, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2d02af6-32d4-4977-b1cd-48d865db0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) 배치 패딩(collate) =====\n",
    "import torch\n",
    "\n",
    "def collate_batch(\n",
    "    batch,\n",
    "    pad_id: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    batch: [{\"input_ids\": List[int], \"attention_mask\": List[int], \"label\": int}, ...]\n",
    "    \"\"\"\n",
    "    bs = len(batch)\n",
    "    maxlen = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = torch.full((bs, maxlen), pad_id, dtype=torch.long)\n",
    "    attention_mask = torch.zeros((bs, maxlen), dtype=torch.long)\n",
    "    labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.long)\n",
    "\n",
    "    for i, x in enumerate(batch):\n",
    "        L = len(x[\"input_ids\"])\n",
    "        input_ids[i, :L] = torch.tensor(x[\"input_ids\"], dtype=torch.long)\n",
    "        attention_mask[i, :L] = torch.tensor(x[\"attention_mask\"], dtype=torch.long)\n",
    "\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7174d1e9-5a97-4550-b7fd-1c46cee100a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 9439 | Labels: {'협박 대화': 0, '갈취 대화': 1, '직장 내 괴롭힘 대화': 2, '기타 괴롭힘 대화': 3, '일반 대화': 4}\n",
      "torch.Size([16, 67])\n"
     ]
    }
   ],
   "source": [
    "# ===== 4) 예시 파이프라인 (라벨 매핑 포함) =====\n",
    "# 4-1) tokens 컬럼이 없다면 먼저 생성\n",
    "# raw_data['tokens'] = raw_data['conversation'].apply(lambda s: preprocess_sentence(str(s), stop_words))\n",
    "\n",
    "# 4-2) 라벨 매핑\n",
    "labels = sorted(raw_data[\"class\"].unique().tolist())\n",
    "label2id = {\n",
    "    \"협박 대화\": 0,\n",
    "    \"갈취 대화\": 1,\n",
    "    \"직장 내 괴롭힘 대화\": 2,\n",
    "    \"기타 괴롭힘 대화\": 3,\n",
    "    \"일반 대화\": 4,\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# 4-3) vocab 빌드\n",
    "stoi, itos, counter = build_vocab(raw_data[\"tokens\"], min_freq=1, max_size=20000)\n",
    "pad_id = stoi[\"<pad>\"]\n",
    "\n",
    "# 4-4) 인코딩 (train/valid 분할은 이미 되어있다고 가정하거나 아래처럼 간단 분할)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(raw_data, test_size=0.2, random_state=42, stratify=raw_data[\"class\"])\n",
    "\n",
    "def encode_row(row, max_len=256):\n",
    "    ids, attn = encode_tokens(row[\"tokens\"], stoi, max_len=max_len, add_cls=True, add_sep=True)\n",
    "    return {\n",
    "        \"input_ids\": ids,\n",
    "        \"attention_mask\": attn,\n",
    "        \"label\": label2id[row[\"class\"]],\n",
    "    }\n",
    "\n",
    "train_records = [encode_row(r) for _, r in train_df.iterrows()]\n",
    "valid_records = [encode_row(r) for _, r in valid_df.iterrows()]\n",
    "\n",
    "# 4-5) PyTorch Dataset/Dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleListDataset(Dataset):\n",
    "    def __init__(self, records):\n",
    "        self.records = records\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.records[idx]\n",
    "\n",
    "train_ds = SimpleListDataset(train_records)\n",
    "valid_ds = SimpleListDataset(valid_records)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,\n",
    "                          collate_fn=lambda b: collate_batch(b, pad_id))\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=False,\n",
    "                          collate_fn=lambda b: collate_batch(b, pad_id))\n",
    "\n",
    "print(f\"Vocab size: {len(itos)} | Labels: {label2id}\")\n",
    "print(next(iter(train_loader))[\"input_ids\"].shape)  # (B, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c8b85",
   "metadata": {},
   "source": [
    "# 모델 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d36f6fea-ab46-4751-8b7f-1f07ee3f72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Positional Encoding (sin/cos)\n",
    "# ----------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 512, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len,1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "        # 미세한 안정화용\n",
    "        nn.init.zeros_(self.pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, S, E)\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5da2d1df-9e6e-4c1e-8152-cb0ee761d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transformer Encoder Classifier\n",
    "# ----------------------------\n",
    "class TransformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    순수 Transformer-Encoder 기반 문서/대화 분류기.\n",
    "    - input_ids: (B, S) 토큰 인덱스\n",
    "    - attention_mask: (B, S) 1=유효, 0=패딩\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        num_classes: int,\n",
    "        emb_dim: int = 256,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        dim_feedforward: int = 512,\n",
    "        max_len: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "        pad_id: int = 0,\n",
    "        use_cls_pool: bool = True,  # True면 첫 토큰(<cls>)을 문장 표현으로 사용, False면 마스크 평균\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert emb_dim % nhead == 0, \"emb_dim must be divisible by nhead\"\n",
    "\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.pos = PositionalEncoding(emb_dim, max_len=max_len, dropout=dropout)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=False,  # 입력은 (S,B,E)\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        self.norm = nn.LayerNorm(emb_dim)\n",
    "        self.classifier = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "        self.emb_scale = math.sqrt(emb_dim)\n",
    "        self.use_cls_pool = use_cls_pool\n",
    "\n",
    "        # Xavier init (선택)\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        return_repr: bool = False,\n",
    "    ):\n",
    "        # (B,S) -> (B,S,E)\n",
    "        x = self.emb(input_ids) * self.emb_scale\n",
    "        x = self.pos(x)                         # (B,S,E)\n",
    "        x = x.transpose(0, 1)                   # (S,B,E)\n",
    "\n",
    "        key_padding_mask = None\n",
    "        if attention_mask is not None:\n",
    "            key_padding_mask = (attention_mask == 0)  # True=mask\n",
    "\n",
    "        x = self.encoder(x, src_key_padding_mask=key_padding_mask)  # (S,B,E)\n",
    "        x = x.transpose(0, 1)                                       # (B,S,E)\n",
    "\n",
    "        if self.use_cls_pool:\n",
    "            sent_repr = x[:, 0, :]  # <cls> 위치\n",
    "        else:\n",
    "            if attention_mask is None:\n",
    "                sent_repr = x.mean(dim=1)\n",
    "            else:\n",
    "                mask = attention_mask.unsqueeze(-1).float()         # (B,S,1)\n",
    "                sent_repr = (x * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
    "\n",
    "        sent_repr = self.norm(sent_repr)\n",
    "        logits = self.classifier(sent_repr)\n",
    "\n",
    "        if return_repr:\n",
    "            return logits, sent_repr\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7063c91e-b16d-4371-b196-755941f48d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 학습/평가 루프\n",
    "# ----------------------------\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    class_weights: Optional[torch.Tensor] = None,\n",
    "    grad_clip: float = 1.0,\n",
    "    scheduler = None,\n",
    "    use_amp: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    ce = nn.CrossEntropyLoss(weight=class_weights.to(device) if class_weights is not None else None)\n",
    "\n",
    "    losses, all_preds, all_labels = [], [], []\n",
    "    for batch in tqdm(dataloader, desc=\"train\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn = batch.get(\"attention_mask\")\n",
    "        attn = attn.to(device) if attn is not None else None\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            logits = model(input_ids, attention_mask=attn)\n",
    "            loss = ce(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if grad_clip is not None:\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        all_preds += logits.argmax(dim=-1).detach().cpu().tolist()\n",
    "        all_labels += labels.detach().cpu().tolist()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    return {\"loss\": sum(losses)/len(losses), \"acc\": acc, \"f1_macro\": f1}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses, all_preds, all_labels = [], [], []\n",
    "    for batch in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn = batch.get(\"attention_mask\")\n",
    "        attn = attn.to(device) if attn is not None else None\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask=attn)\n",
    "        loss = ce(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_preds += logits.argmax(dim=-1).detach().cpu().tolist()\n",
    "        all_labels += labels.detach().cpu().tolist()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds) if all_labels else 0.0\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\") if all_labels else 0.0\n",
    "    return {\"loss\": sum(losses)/len(losses), \"acc\": acc, \"f1_macro\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d90593ed-d7e6-444c-bc92-9c40cadd0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 모델 팩토리 (간단 생성기)\n",
    "# ----------------------------\n",
    "def create_model(\n",
    "    vocab_size: int,\n",
    "    num_classes: int = 5,          # 협박0, 갈취1, 직장2, 기타3, 일반4\n",
    "    pad_id: int = 0,\n",
    "    emb_dim: int = 256,\n",
    "    nhead: int = 8,\n",
    "    num_layers: int = 4,\n",
    "    dim_ff: int = 512,\n",
    "    max_len: int = 512,\n",
    "    dropout: float = 0.1,\n",
    "    use_cls_pool: bool = True,\n",
    ") -> nn.Module:\n",
    "    return TransformerClassifier(\n",
    "        vocab_size=vocab_size,\n",
    "        num_classes=num_classes,\n",
    "        emb_dim=emb_dim,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_feedforward=dim_ff,\n",
    "        max_len=max_len,\n",
    "        dropout=dropout,\n",
    "        pad_id=pad_id,\n",
    "        use_cls_pool=use_cls_pool,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10671bf9-831f-41a5-84f3-ac4b460d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가정: stoi, itos, train_loader, valid_loader, label2id 존재\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = create_model(\n",
    "    vocab_size=len(itos),\n",
    "    num_classes=5,                # 고정 매핑(협박0, 갈취1, 직장2, 기타3, 일반4)\n",
    "    pad_id=stoi[\"<pad>\"],\n",
    "    emb_dim=256,\n",
    "    nhead=8,\n",
    "    num_layers=3,                 # 처음엔 3~4로 시작 추천\n",
    "    dim_ff=512,\n",
    "    max_len=256,                  # 인코딩에서 쓴 max_len과 동일하게\n",
    "    dropout=0.1,\n",
    "    use_cls_pool=True,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "scheduler = None  # 필요하면 CosineAnnealingLR 등 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3da6f069-1579-4b13-8299-834c9ba5660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e5b449342a495a8a01c49519f9a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f06f1322e04e0681aaa23eea9b4d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] train: {'loss': 0.9301957825138685, 'acc': 0.6330808080808081, 'f1_macro': 0.6336061230290428} | valid: {'loss': 0.6416148658721678, 'acc': 0.7686868686868686, 'f1_macro': 0.764760563816296}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0630b2075d49e59ca061a83a7de36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa39360a5d6743748df2f282d391e5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02] train: {'loss': 0.5191494069632984, 'acc': 0.8088383838383838, 'f1_macro': 0.8087058848352159} | valid: {'loss': 0.5456315480893658, 'acc': 0.8090909090909091, 'f1_macro': 0.8063818715696763}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acfffa788c24874b024619322a4f99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e8df064c0442c6b0d022ad102c58b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03] train: {'loss': 0.4044243809691961, 'acc': 0.8547979797979798, 'f1_macro': 0.8543334950991003} | valid: {'loss': 0.4534387064556922, 'acc': 0.8474747474747475, 'f1_macro': 0.8454618880771354}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06579ea193494f98a923fb7f0b8647c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6519e8a330454cefa9e6c64573717f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04] train: {'loss': 0.32468314080559196, 'acc': 0.8810606060606061, 'f1_macro': 0.8805851803268885} | valid: {'loss': 0.5495267904573872, 'acc': 0.8404040404040404, 'f1_macro': 0.8413948453163812}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04322a560def40dfa78e754a5d169ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc775fef50444cf08b00fd400888259d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05] train: {'loss': 0.2976029585190718, 'acc': 0.9027777777777778, 'f1_macro': 0.90256472296202} | valid: {'loss': 0.5579364064239687, 'acc': 0.8393939393939394, 'f1_macro': 0.8391638575799909}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e766c455785c4a69aa02b256cf984bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e00f5340f9b41cb88ced3b52775f373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06] train: {'loss': 0.24060421482652367, 'acc': 0.9212121212121213, 'f1_macro': 0.9209052975927889} | valid: {'loss': 0.5640041424382117, 'acc': 0.8515151515151516, 'f1_macro': 0.8505108721974295}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debda2f98c114d63952c86c8a6467056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7a15d93984380ab297642c26aa72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07] train: {'loss': 0.2294417011700364, 'acc': 0.9222222222222223, 'f1_macro': 0.921596288718266} | valid: {'loss': 0.6073578524012719, 'acc': 0.8535353535353535, 'f1_macro': 0.8528260642566723}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5156a2ab5e1944088fc2deff4628aebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78ec415c65646e5b8c15a03368122d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08] train: {'loss': 0.2036944322964935, 'acc': 0.9305555555555556, 'f1_macro': 0.9305423206299} | valid: {'loss': 0.7311634459803181, 'acc': 0.8313131313131313, 'f1_macro': 0.830800050553765}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e559ae3142742028f0aac9f54d0c677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0def4e45fd8c413eb8f0e1601b21246c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09] train: {'loss': 0.19143817817060946, 'acc': 0.9361111111111111, 'f1_macro': 0.9360156091091394} | valid: {'loss': 0.7166833156539548, 'acc': 0.8494949494949495, 'f1_macro': 0.8478019869466866}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea9802dba2642b78acdc9cadd2fc608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3ba7a5171b4095adfe7da46441a366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] train: {'loss': 0.16468576415589328, 'acc': 0.9477272727272728, 'f1_macro': 0.9475904419700807} | valid: {'loss': 0.8618458595968062, 'acc': 0.8454545454545455, 'f1_macro': 0.8440827764467121}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f668f2d44e4014bc8149d24e95a8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95e8bef77ac40b2afa98ed3248e1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] train: {'loss': 0.14835209358464072, 'acc': 0.951010101010101, 'f1_macro': 0.9507619215992464} | valid: {'loss': 0.8422013939388336, 'acc': 0.8535353535353535, 'f1_macro': 0.8527977669177009}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8cdcf78e0c42419ac3b3fe6a19fc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912b1670bac84944acf7cc82170b3cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] train: {'loss': 0.15495107117796228, 'acc': 0.954040404040404, 'f1_macro': 0.9539884328461256} | valid: {'loss': 0.8799200328367371, 'acc': 0.8515151515151516, 'f1_macro': 0.8522981265462395}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310af0e7fe014d1185edd4f110c360be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca805f455f4f4da4badb692d1f2560e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] train: {'loss': 0.18471884747894166, 'acc': 0.9507575757575758, 'f1_macro': 0.9508337342049273} | valid: {'loss': 0.9671993837241204, 'acc': 0.8494949494949495, 'f1_macro': 0.8503689563324593}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9daac196824c8bb1a4a85d93dd325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216f1f0bd3654abeb29871c6f1edccda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] train: {'loss': 0.12105335155519564, 'acc': 0.9643939393939394, 'f1_macro': 0.9643087539406491} | valid: {'loss': 1.0611533474537633, 'acc': 0.8505050505050505, 'f1_macro': 0.85066642559954}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5251261463cd4711ac7ba67e0e8843c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93b7efb61a649c191fa2d86be6e9d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] train: {'loss': 0.12825964305372303, 'acc': 0.9618686868686869, 'f1_macro': 0.9616011339239767} | valid: {'loss': 1.0734306716870876, 'acc': 0.8525252525252526, 'f1_macro': 0.8527000455114695}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d969e91be9d475b8303cc2a31193e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8b423ae5dc495faebd59f5fbc5c837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] train: {'loss': 0.11960528742517981, 'acc': 0.9613636363636363, 'f1_macro': 0.9613951576273294} | valid: {'loss': 1.1942860896308576, 'acc': 0.8414141414141414, 'f1_macro': 0.8405783937744016}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd31f8e408674f7a95c6471fa79aaf6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7128a787625a4059a967ec708ce5208d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] train: {'loss': 0.128610664224016, 'acc': 0.9623737373737373, 'f1_macro': 0.9622661984296907} | valid: {'loss': 1.149308985760135, 'acc': 0.8565656565656565, 'f1_macro': 0.8562053276346113}\n",
      "  ✔ saved best model (F1 ↑)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f868f6313c544b3bea862c94568037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cd0522709242d5a2d1f4a8f609230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] train: {'loss': 0.10979072569548655, 'acc': 0.9719696969696969, 'f1_macro': 0.9719674423248877} | valid: {'loss': 1.264604136588112, 'acc': 0.8515151515151516, 'f1_macro': 0.8499581968445924}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542a61120daf44f9a715431ae296bd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c765ab2f544f7995161af470657971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19] train: {'loss': 0.13589570325825295, 'acc': 0.9659090909090909, 'f1_macro': 0.9660623753072594} | valid: {'loss': 1.161094265118722, 'acc': 0.8505050505050505, 'f1_macro': 0.8492052240007546}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ee60c2110d424abd9bc517ba4de651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae0ef3cabd6490595bd209c221b6e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20] train: {'loss': 0.10922668906873549, 'acc': 0.9671717171717171, 'f1_macro': 0.9671082075257157} | valid: {'loss': 1.2462107303642458, 'acc': 0.8494949494949495, 'f1_macro': 0.8489132378360772}\n"
     ]
    }
   ],
   "source": [
    "# (선택) 클래스 가중치: train_df의 정수 라벨 리스트로 계산\n",
    "from collections import Counter\n",
    "train_labels = [rec[\"label\"] for rec in train_records]  # 이전 단계 encode_records 기준\n",
    "cnt = Counter(train_labels)\n",
    "weights = torch.tensor([1.0 / max(cnt.get(i, 1), 1) for i in range(5)], dtype=torch.float)\n",
    "weights = weights / weights.mean()  # 평균 1로 정규화\n",
    "class_weights = weights\n",
    "\n",
    "best_f1 = 0.0\n",
    "epochs = 20\n",
    "for ep in range(1, epochs+1):\n",
    "    tr = train_one_epoch(model, train_loader, optimizer, device,\n",
    "                         class_weights=class_weights, grad_clip=1.0, scheduler=scheduler, use_amp=True)\n",
    "    va = evaluate(model, valid_loader, device)\n",
    "    print(f\"[{ep:02d}] train: {tr} | valid: {va}\")\n",
    "\n",
    "    if va[\"f1_macro\"] > best_f1:\n",
    "        best_f1 = va[\"f1_macro\"]\n",
    "        torch.save(model.state_dict(), \"./\"+str(best_f1)+\"best_transformer_cls.pt\")\n",
    "        print(\"  ✔ saved best model (F1 ↑)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64939f6-5dad-47fa-8e55-3f929b14c5aa",
   "metadata": {},
   "source": [
    "todo: test.csv 불러와서 예측값만 submission.csv에 저장하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30491f9d-28fa-45b0-b4d2-007457c0e6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799102a-6aa3-46a7-98dd-b732bfcfa831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f24ea-62e1-46de-9d08-a6544be94165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee21531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
